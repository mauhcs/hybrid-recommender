{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we split the `item_history.tsv` file in train and test files called `y_train.tsv` and `y_test.tsv` and save it in the `data` folder\n",
    "\n",
    "Also we generate the `train_frequencies.tsv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T08:52:43.509649Z",
     "start_time": "2020-08-22T08:52:42.800814Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y_train / y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T12:38:00.488538Z",
     "start_time": "2020-08-22T12:37:28.412191Z"
    }
   },
   "outputs": [],
   "source": [
    "target_users = pd.read_csv(\"data/target_users.tsv\", sep=\"\\t\")\n",
    "\n",
    "user_master  = pd.read_csv(\"data/user_master.tsv\", sep=\"\\t\")\n",
    "# Sort on user_id\n",
    "user_master.sort_values(\"user_id\", inplace=True)\n",
    "user_master.reset_index(drop=True, inplace=True)\n",
    "\n",
    "item_hist    = pd.read_csv(\"data/item_history.tsv\", sep=\"\\t\")\n",
    "# Sort by Timestamp\n",
    "item_hist = item_hist.sort_values(\"latest_timestamp\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T08:53:34.982837Z",
     "start_time": "2020-08-22T08:53:21.174659Z"
    }
   },
   "outputs": [],
   "source": [
    "all_items = item_hist.item_id.sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T08:53:34.997393Z",
     "start_time": "2020-08-22T08:53:34.984786Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = int(len(item_hist)*0.7)\n",
    "test_size = int(len(item_hist)*0.2)\n",
    "validation_size = len(item_hist) - train_size - test_size\n",
    "\n",
    "#ihist_train = \n",
    "\n",
    "ihist_train = item_hist[:train_size]\n",
    "ihist_test  = item_hist[train_size:train_size+test_size]\n",
    "ihist_val   = item_hist[train_size+test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.make_Y import make_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T16:21:34.038776Z",
     "start_time": "2020-08-22T12:43:07.853071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Writer\n",
      "1,640,000 / 1,640,956 (99.94)%\n",
      "Stoping Writer\n",
      "Done with y_train\n",
      "Starting Writer\n",
      "1,640,000 / 1,640,956 (99.94)%\n",
      "Stoping Writer\n"
     ]
    }
   ],
   "source": [
    "make_Y(user_master.user_id.unique(), ihist_train, \"y_train\")\n",
    "print(\"Done with y_train\")\n",
    "make_Y(user_master.user_id.unique(), ihist_test, \"y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T12:24:33.032288Z",
     "start_time": "2020-08-22T12:24:32.939834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1640956"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_master.user_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T12:25:00.848546Z",
     "start_time": "2020-08-22T12:25:00.820458Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250343"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_users.user_id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_frequencies.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T11:37:38.625050Z",
     "start_time": "2020-09-01T11:37:35.451240Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark # only run after findspark.init()\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# In Jupyter you have to stop the current context first\n",
    "# sc.stop()\n",
    "\n",
    "# Create new config\n",
    "conf = SparkConf().set(\"spark.driver.maxResultSize\", \"20g\")\n",
    "\n",
    "sc = SparkContext(appName=\"PythonCleaner\", sparkHome=\"/usr/local/spark\", conf=conf)    \n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T11:37:51.753377Z",
     "start_time": "2020-09-01T11:37:51.750962Z"
    }
   },
   "outputs": [],
   "source": [
    "from model.als_trainer import ALSTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-01T11:41:07.966410Z",
     "start_time": "2020-09-01T11:38:28.081280Z"
    }
   },
   "outputs": [],
   "source": [
    "frequencies = ALSTrainer.load(sqlContext, split_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this cell to save the frequencies dataframe to a tsv file\n",
    "#frequencies.write.csv(\"data/train_frequencies.tsv\",sep=\"\\t\", header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
